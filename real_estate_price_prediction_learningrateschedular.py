# -*- coding: utf-8 -*-
"""Real Estate Price Prediction_Learningrateschedular.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DzsoFovE90lah3RFRtWSpHDNGe80Revt
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, BatchNormalization
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.optimizers import Adam

house_df = pd.read_csv('realtor_ma_only.csv')

house_df.info()

print(house_df['price'].mean())
print(house_df['price'].min())
print(house_df['bed'].max())
print(np.floor(house_df['bath'].mean()))
house_df.describe()

house_df['bed'].fillna(house_df['bed'].mode()[0], inplace=True)
house_df['bath'].fillna(house_df['bath'].mode()[0], inplace=True)
house_df['acre_lot'].fillna(house_df['acre_lot'].mode()[0], inplace=True)
house_df['house_size'].fillna(house_df['house_size'].mode()[0], inplace=True)

sns.scatterplot(x = 'house_size', y = 'price', data = house_df)

total_missing = house_df.isna().sum()*100/len(house_df)
print('Percentage Missing Value %')
total_missing.sort_values(ascending=False)

house_df = house_df.dropna(subset=['zip_code','city', 'price'])

total_missing = house_df.isna().sum()
total_missing

house_df.hist(bins = 20, figsize = (20,20), color = 'b')

cols = ['bed','bath','acre_lot','house_size','price']

Q1 = house_df[cols].quantile(0.25)
Q3 = house_df[cols].quantile(0.75)
IQR = Q3 - Q1

house_df = house_df[~((house_df[cols] < (Q1 - 1.5 * IQR)) | (house_df[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]

house_df

f, ax = plt.subplots(figsize = (20, 20))
sns.heatmap(house_df.corr(), annot = True)

selected_features = ['bed', 'bath', 'acre_lot','zip_code', 'house_size']

X = house_df[selected_features]

X

y = house_df['price']

y

X.shape

y.shape

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

X_scaled

X_scaled.shape

scaler.data_max_

scaler.data_min_

y = y.values.reshape(-1,1)

y_scaler = MinMaxScaler()
y_scaled = y_scaler.fit_transform(y)

y_scaled

from tensorflow.keras.callbacks import LearningRateScheduler
def scheduler(epoch, lr):
  if epoch < 50:
    return lr
  else:
    return lr * tf.math.exp(-0.1)
lr_schedule = LearningRateScheduler(scheduler)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size = 0.25)

X_train.shape

X_test.shape

import tensorflow.keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential()
model.add(Dense(100, input_dim = 5, activation = 'relu'))
model.add(Dense(100, activation = 'relu'))
model.add(Dense(100, activation = 'relu'))
model.add(Dense(200, activation = 'relu'))
model.add(Dense(200, activation = 'relu'))
model.add(Dense(1, activation = 'linear'))

model.summary()

#model.compile(optimizer = 'Adam', loss = 'mean_squared_error')
optimizer = tensorflow.keras.optimizers.Adam(clipvalue=0.5)
model.compile(optimizer=optimizer, loss='mean_squared_error')

epochs_hist = model.fit(X_train, y_train, epochs = 100, batch_size = 50, validation_split = 0.2, callbacks=[lr_schedule])

plt.plot(epochs_hist.history['loss'])
plt.plot(epochs_hist.history['val_loss'])
plt.title('Model Loss Progress During Training')
plt.xlabel('Epoch')
plt.ylabel('Training and Validation Loss')
plt.legend(['Training Loss', 'Validation Loss'])

# 'bed', 'bath', 'acre_lot','zip_code', 'house_size',
X_test_1 = np.array([[ 4, 3,.63, 2655,2624]])
X_test_scaled_1 = scaler.transform(X_test_1)
X_test_scaled_1

y_predict_1 = model.predict(X_test_scaled_1)
y_predict_1
y_predict_1 = y_scaler.inverse_transform(y_predict_1)
y_predict_1

y_predict = model.predict(X_test)
plt.plot(y_test, y_predict, "^", color = 'r')
plt.xlabel('Model Predictions')
plt.ylabel('True Values')

y_predict_orig = y_scaler.inverse_transform(y_predict)
y_test_orig = y_scaler.inverse_transform(y_test)

k = X_test.shape[1]
n = len(X_test)
n

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from math import sqrt

RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_predict_orig)),'.3f'))
MSE = mean_squared_error(y_test_orig, y_predict_orig)
MAE = mean_absolute_error(y_test_orig, y_predict_orig)
r2 = r2_score(y_test_orig, y_predict_orig)
adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)

print('RMSE =',RMSE, '\nMSE =',MSE, '\nMAE =',MAE, '\nR2 =', r2, '\nAdjusted R2 =', adj_r2)